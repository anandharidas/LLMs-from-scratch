{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/anandharidas/LLMs-from-scratch/blob/main/ch02/01_main-chapter-code/dataloader.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6e2a4891-c257-4d6b-afb3-e8fef39d0437",
      "metadata": {
        "id": "6e2a4891-c257-4d6b-afb3-e8fef39d0437"
      },
      "source": [
        "<table style=\"width:100%\">\n",
        "<tr>\n",
        "<td style=\"vertical-align:middle; text-align:left;\">\n",
        "<font size=\"2\">\n",
        "Supplementary code for the <a href=\"http://mng.bz/orYv\">Build a Large Language Model From Scratch</a> book by <a href=\"https://sebastianraschka.com\">Sebastian Raschka</a><br>\n",
        "<br>Code repository: <a href=\"https://github.com/rasbt/LLMs-from-scratch\">https://github.com/rasbt/LLMs-from-scratch</a>\n",
        "</font>\n",
        "</td>\n",
        "<td style=\"vertical-align:middle; text-align:left;\">\n",
        "<a href=\"http://mng.bz/orYv\"><img src=\"https://sebastianraschka.com/images/LLMs-from-scratch-images/cover-small.webp\" width=\"100px\"></a>\n",
        "</td>\n",
        "</tr>\n",
        "</table>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6f678e62-7bcb-4405-86ae-dce94f494303",
      "metadata": {
        "id": "6f678e62-7bcb-4405-86ae-dce94f494303"
      },
      "source": [
        "# The Main Data Loading Pipeline Summarized"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "070000fc-a7b7-4c56-a2c0-a938d413a790",
      "metadata": {
        "id": "070000fc-a7b7-4c56-a2c0-a938d413a790"
      },
      "source": [
        "The complete chapter code is located in [ch02.ipynb](./ch02.ipynb).\n",
        "\n",
        "This notebook contains the main takeaway, the data loading pipeline without the intermediate steps."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2b4e8f2d-cb81-41a3-8780-a70b382e18ae",
      "metadata": {
        "id": "2b4e8f2d-cb81-41a3-8780-a70b382e18ae"
      },
      "source": [
        "Packages that are being used in this notebook:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c7ed6fbe-45ac-40ce-8ea5-4edb212565e1",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c7ed6fbe-45ac-40ce-8ea5-4edb212565e1",
        "outputId": "52a197a7-ff42-424f-cbeb-3fd21d4e8645"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch version: 2.9.0+cpu\n",
            "tiktoken version: 0.12.0\n"
          ]
        }
      ],
      "source": [
        "# NBVAL_SKIP\n",
        "from importlib.metadata import version\n",
        "\n",
        "print(\"torch version:\", version(\"torch\"))\n",
        "print(\"tiktoken version:\", version(\"tiktoken\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0ed4b7db-3b47-4fd3-a4a6-5f4ed5dd166e",
      "metadata": {
        "id": "0ed4b7db-3b47-4fd3-a4a6-5f4ed5dd166e"
      },
      "outputs": [],
      "source": [
        "import tiktoken\n",
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "\n",
        "class GPTDatasetV1(Dataset):\n",
        "    def __init__(self, txt, tokenizer, max_length, stride):\n",
        "        self.input_ids = []\n",
        "        self.target_ids = []\n",
        "\n",
        "        # Tokenize the entire text\n",
        "        token_ids = tokenizer.encode(txt, allowed_special={\"<|endoftext|>\"})\n",
        "\n",
        "        # Use a sliding window to chunk the book into overlapping sequences of max_length\n",
        "        for i in range(0, len(token_ids) - max_length, stride):\n",
        "            input_chunk = token_ids[i:i + max_length]\n",
        "            target_chunk = token_ids[i + 1: i + max_length + 1]\n",
        "            self.input_ids.append(torch.tensor(input_chunk))\n",
        "            self.target_ids.append(torch.tensor(target_chunk))\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.input_ids)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return self.input_ids[idx], self.target_ids[idx]\n",
        "\n",
        "\n",
        "def create_dataloader_v1(txt, batch_size, max_length, stride,\n",
        "                         shuffle=True, drop_last=True, num_workers=0):\n",
        "    # Initialize the tokenizer\n",
        "    tokenizer = tiktoken.get_encoding(\"gpt2\")\n",
        "\n",
        "    # Create dataset\n",
        "    dataset = GPTDatasetV1(txt, tokenizer, max_length, stride)\n",
        "\n",
        "    # Create dataloader\n",
        "    dataloader = DataLoader(\n",
        "        dataset, batch_size=batch_size, shuffle=shuffle, drop_last=drop_last, num_workers=num_workers)\n",
        "\n",
        "    return dataloader\n",
        "\n",
        "\n",
        "with open(\"the-verdict.txt\", \"r\", encoding=\"utf-8\") as f:\n",
        "    raw_text = f.read()\n",
        "\n",
        "vocab_size = 50257\n",
        "output_dim = 256\n",
        "context_length = 1024\n",
        "\n",
        "\n",
        "token_embedding_layer = torch.nn.Embedding(vocab_size, output_dim)\n",
        "pos_embedding_layer = torch.nn.Embedding(context_length, output_dim)\n",
        "\n",
        "batch_size = 8\n",
        "max_length = 4\n",
        "dataloader = create_dataloader_v1(\n",
        "    raw_text,\n",
        "    batch_size=batch_size,\n",
        "    max_length=max_length,\n",
        "    stride=max_length\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "664397bc-6daa-4b88-90aa-e8fc1fbd5846",
      "metadata": {
        "id": "664397bc-6daa-4b88-90aa-e8fc1fbd5846"
      },
      "outputs": [],
      "source": [
        "for batch in dataloader:\n",
        "    x, y = batch\n",
        "\n",
        "    token_embeddings = token_embedding_layer(x)\n",
        "    pos_embeddings = pos_embedding_layer(torch.arange(max_length))\n",
        "\n",
        "    input_embeddings = token_embeddings + pos_embeddings\n",
        "\n",
        "    break"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install gensim"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bpgOCf-DSO3a",
        "outputId": "f46a0770-a419-4ea0-c1b1-154ff9b703e6"
      },
      "id": "bpgOCf-DSO3a",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: gensim in /usr/local/lib/python3.12/dist-packages (4.4.0)\n",
            "Requirement already satisfied: numpy>=1.18.5 in /usr/local/lib/python3.12/dist-packages (from gensim) (2.0.2)\n",
            "Requirement already satisfied: scipy>=1.7.0 in /usr/local/lib/python3.12/dist-packages (from gensim) (1.16.3)\n",
            "Requirement already satisfied: smart_open>=1.8.1 in /usr/local/lib/python3.12/dist-packages (from gensim) (7.5.0)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.12/dist-packages (from smart_open>=1.8.1->gensim) (2.0.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import gensim.downloader as api\n",
        "\n",
        "model = api.load(\"word2vec-google-news-300\")"
      ],
      "metadata": {
        "id": "HNZoUG84SNKC"
      },
      "id": "HNZoUG84SNKC",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(model.most_similar(positive=['king','woman'] , negative=['man'], topn=10))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2jku-wfihPUw",
        "outputId": "5a69347f-fd89-4927-bbf2-9e60ac31ee14"
      },
      "id": "2jku-wfihPUw",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[('queen', 0.7118193507194519), ('monarch', 0.6189674139022827), ('princess', 0.5902431011199951), ('crown_prince', 0.5499460697174072), ('prince', 0.5377321839332581), ('kings', 0.5236844420433044), ('Queen_Consort', 0.5235945582389832), ('queens', 0.518113374710083), ('sultan', 0.5098593235015869), ('monarchy', 0.5087411403656006)]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install gensim"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R2DRdNTE4Tyh",
        "outputId": "a0aca638-3e4f-4c86-d5dd-ad4b461f9860"
      },
      "id": "R2DRdNTE4Tyh",
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting gensim\n",
            "  Downloading gensim-4.4.0-cp312-cp312-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl.metadata (8.4 kB)\n",
            "Requirement already satisfied: numpy>=1.18.5 in /usr/local/lib/python3.12/dist-packages (from gensim) (2.0.2)\n",
            "Requirement already satisfied: scipy>=1.7.0 in /usr/local/lib/python3.12/dist-packages (from gensim) (1.16.3)\n",
            "Requirement already satisfied: smart_open>=1.8.1 in /usr/local/lib/python3.12/dist-packages (from gensim) (7.5.0)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.12/dist-packages (from smart_open>=1.8.1->gensim) (2.0.1)\n",
            "Downloading gensim-4.4.0-cp312-cp312-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl (27.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m27.9/27.9 MB\u001b[0m \u001b[31m24.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: gensim\n",
            "Successfully installed gensim-4.4.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import gensim.downloader as api"
      ],
      "metadata": {
        "id": "HfhO9d7k4XUM"
      },
      "id": "HfhO9d7k4XUM",
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = api.load(\"word2vec-google-news-300\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N8k_i4Jx4e2q",
        "outputId": "f049f030-a72b-4617-ba84-f743f9ef4730"
      },
      "id": "N8k_i4Jx4e2q",
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[==================================================] 100.0% 1662.8/1662.8MB downloaded\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.most_similar(\"tower\",topn=10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nCupC5FJLRWs",
        "outputId": "263e0bfa-10c3-4f2b-c7a5-dde7799302aa"
      },
      "id": "nCupC5FJLRWs",
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('towers', 0.8531750440597534),\n",
              " ('skyscraper', 0.6417425870895386),\n",
              " ('Tower', 0.639177143573761),\n",
              " ('spire', 0.594687819480896),\n",
              " ('responded_Understood_Atlasjet', 0.5931612253189087),\n",
              " ('storey_tower', 0.5783934593200684),\n",
              " ('SolarReserve_molten_salt', 0.5733036398887634),\n",
              " ('monopole_tower', 0.566946804523468),\n",
              " ('bell_tower', 0.5626809000968933),\n",
              " ('foot_monopole', 0.5514882802963257)]"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model[\"om\"]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Oiim19yGNgOZ",
        "outputId": "1250a859-0a9a-4518-c415-6845e29a1dc1"
      },
      "id": "Oiim19yGNgOZ",
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([ 5.51757812e-02,  1.88476562e-01, -1.87988281e-02, -6.05468750e-02,\n",
              "       -3.44238281e-02, -1.80664062e-01,  2.40325928e-04, -9.08203125e-02,\n",
              "       -3.32031250e-01, -6.34765625e-02, -3.43750000e-01, -1.49414062e-01,\n",
              "       -4.51171875e-01,  2.70996094e-02, -3.08593750e-01, -6.39648438e-02,\n",
              "        1.87500000e-01,  1.49414062e-01, -3.46679688e-02, -3.14941406e-02,\n",
              "       -9.03320312e-02, -3.93066406e-02, -1.21093750e-01,  1.24023438e-01,\n",
              "       -2.23632812e-01, -1.22558594e-01, -1.66015625e-01, -8.48388672e-03,\n",
              "       -9.27734375e-02, -2.59765625e-01,  1.50390625e-01,  1.15234375e-01,\n",
              "       -2.47070312e-01, -2.83203125e-01, -3.86718750e-01, -1.69921875e-01,\n",
              "       -2.31445312e-01,  3.65234375e-01,  3.45703125e-01,  2.53906250e-02,\n",
              "       -2.13867188e-01, -5.11718750e-01, -1.62109375e-01,  1.11328125e-01,\n",
              "        6.59179688e-02,  1.17675781e-01, -2.20703125e-01, -1.92382812e-01,\n",
              "       -1.89208984e-02,  5.19531250e-01,  4.46777344e-02,  4.62890625e-01,\n",
              "        2.38037109e-02,  3.32031250e-01,  9.71679688e-02, -1.74560547e-02,\n",
              "       -1.48437500e-01, -1.61132812e-01,  8.10546875e-02, -2.34375000e-01,\n",
              "       -2.73437500e-01,  9.86328125e-02, -3.05175781e-03, -1.79443359e-02,\n",
              "       -2.62451172e-02, -2.71484375e-01, -8.54492188e-02,  4.39453125e-02,\n",
              "       -3.68652344e-02,  3.37890625e-01, -2.03857422e-02,  7.27539062e-02,\n",
              "        8.93554688e-02,  8.44726562e-02,  5.34667969e-02, -2.95410156e-02,\n",
              "        2.77343750e-01,  1.86523438e-01, -1.36718750e-01,  7.56835938e-03,\n",
              "        4.66308594e-02,  9.71679688e-02,  3.39355469e-02, -1.74804688e-01,\n",
              "        8.49609375e-02,  2.39257812e-01, -1.77734375e-01,  3.83300781e-02,\n",
              "        1.69677734e-02,  1.81884766e-02,  5.54199219e-02,  2.63671875e-01,\n",
              "        5.17578125e-02, -1.60156250e-01,  8.20312500e-02,  2.01416016e-02,\n",
              "       -1.28906250e-01,  9.03320312e-02,  1.77734375e-01,  4.90722656e-02,\n",
              "       -1.42578125e-01, -3.61328125e-02,  2.16064453e-02,  3.22265625e-01,\n",
              "       -3.51562500e-02,  1.44531250e-01, -2.89062500e-01,  2.20703125e-01,\n",
              "        2.23632812e-01, -6.39648438e-02, -3.00292969e-02, -2.83203125e-01,\n",
              "        2.25585938e-01, -1.80664062e-01,  1.62109375e-01,  7.71484375e-02,\n",
              "        6.01196289e-03,  4.02832031e-02,  5.53131104e-04, -2.34375000e-02,\n",
              "       -5.79833984e-03, -8.92639160e-04,  9.61914062e-02,  5.71289062e-02,\n",
              "        2.45117188e-01, -1.75781250e-01, -1.49536133e-02, -2.78320312e-02,\n",
              "        6.12792969e-02,  1.55273438e-01, -3.93066406e-02, -6.22558594e-03,\n",
              "       -7.66601562e-02,  7.42187500e-02, -1.63085938e-01, -3.14941406e-02,\n",
              "        5.61523438e-02,  6.83593750e-02,  1.33789062e-01,  1.50390625e-01,\n",
              "        3.39843750e-01, -9.70458984e-03,  1.05957031e-01, -1.84570312e-01,\n",
              "       -2.50000000e-01, -6.50024414e-03, -1.22558594e-01,  3.66210938e-02,\n",
              "        8.85009766e-03, -9.71679688e-02,  3.12500000e-01, -3.26171875e-01,\n",
              "        1.70898438e-02, -2.14843750e-01,  3.63769531e-02, -2.25585938e-01,\n",
              "        1.19628906e-01,  5.50781250e-01, -1.64062500e-01, -2.21679688e-01,\n",
              "        4.08935547e-03, -1.25000000e-01,  7.27539062e-02, -7.91015625e-02,\n",
              "       -2.94189453e-02, -5.63964844e-02,  1.20117188e-01,  1.56250000e-01,\n",
              "       -3.80859375e-01,  2.96875000e-01, -4.85839844e-02, -8.17871094e-03,\n",
              "       -3.17382812e-03, -1.23535156e-01,  6.73828125e-02,  6.00585938e-02,\n",
              "        2.09960938e-01, -2.11914062e-01,  9.42382812e-02, -2.22656250e-01,\n",
              "        1.50390625e-01, -1.47460938e-01,  5.83496094e-02,  1.14257812e-01,\n",
              "        1.93359375e-01,  3.12500000e-01, -3.03955078e-02,  1.27929688e-01,\n",
              "       -6.29882812e-02,  5.00488281e-02,  1.14257812e-01,  1.08032227e-02,\n",
              "       -1.31835938e-01,  6.40869141e-03,  1.70898438e-01,  1.62109375e-01,\n",
              "       -2.57568359e-02,  5.22460938e-02, -1.45721436e-03, -7.17773438e-02,\n",
              "       -2.14843750e-01, -9.23156738e-04, -4.95605469e-02, -3.61328125e-01,\n",
              "        2.61718750e-01, -1.02539062e-01, -1.51367188e-01,  3.45703125e-01,\n",
              "       -1.40625000e-01,  1.79687500e-01,  8.93554688e-02, -1.23046875e-01,\n",
              "       -3.49609375e-01,  1.48437500e-01, -1.91406250e-01, -6.00585938e-02,\n",
              "        5.56640625e-02, -1.55273438e-01,  1.30004883e-02,  9.52148438e-02,\n",
              "        2.96875000e-01,  6.05468750e-02,  1.28906250e-01,  1.78710938e-01,\n",
              "        1.40625000e-01, -1.06445312e-01,  1.58691406e-03, -1.21307373e-03,\n",
              "       -1.01562500e-01, -1.06445312e-01,  1.49414062e-01, -1.82617188e-01,\n",
              "       -2.48046875e-01, -1.65039062e-01,  2.16796875e-01,  1.31835938e-01,\n",
              "        7.81250000e-02,  1.73828125e-01,  1.16699219e-01,  6.00585938e-02,\n",
              "        7.32421875e-02,  1.94335938e-01, -7.95898438e-02, -1.07910156e-01,\n",
              "        2.05078125e-01,  3.07617188e-02, -1.67968750e-01,  1.74804688e-01,\n",
              "       -1.27929688e-01, -1.99218750e-01,  4.39453125e-02,  2.67578125e-01,\n",
              "        1.67968750e-01, -5.71289062e-02,  8.88671875e-02, -1.26953125e-01,\n",
              "        1.90429688e-02, -2.18750000e-01,  1.90429688e-01,  5.37109375e-02,\n",
              "        1.11816406e-01,  1.36718750e-01,  3.14453125e-01, -4.90722656e-02,\n",
              "       -1.05957031e-01,  1.68945312e-01, -3.22265625e-02,  1.06933594e-01,\n",
              "        8.15429688e-02, -2.22656250e-01,  2.69531250e-01, -2.55859375e-01,\n",
              "       -5.63964844e-02, -7.86132812e-02,  5.90820312e-02, -2.59765625e-01,\n",
              "       -3.80859375e-01, -9.37500000e-02, -3.12500000e-01,  1.68945312e-01,\n",
              "       -1.67968750e-01,  8.78906250e-02,  3.88183594e-02,  7.47680664e-03,\n",
              "        5.67626953e-03, -1.80664062e-02,  2.35351562e-01, -2.11181641e-02,\n",
              "       -3.12500000e-01,  1.91406250e-01,  1.03027344e-01,  7.66601562e-02,\n",
              "       -4.36401367e-03,  1.57928467e-03,  7.22656250e-02, -2.14843750e-01,\n",
              "        2.29492188e-02,  4.15039062e-02, -3.85742188e-02,  1.38671875e-01],\n",
              "      dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.most_similar(\"om\",topn=10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ki9SAa3RNqVl",
        "outputId": "6f1b6075-39d7-4104-b29f-cebc6038a04d"
      },
      "id": "Ki9SAa3RNqVl",
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('på', 0.6145849823951721),\n",
              " ('aan', 0.61150723695755),\n",
              " ('ter', 0.6017832159996033),\n",
              " ('ne', 0.6013097167015076),\n",
              " ('waar', 0.594710648059845),\n",
              " ('moet', 0.5922201871871948),\n",
              " ('te', 0.5908598303794861),\n",
              " ('denne', 0.5897035598754883),\n",
              " ('naar', 0.5896697044372559),\n",
              " ('gaan', 0.5889247059822083)]"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "vector_diff1 = model[\"apple\"] - model[\"mango\"]\n",
        "vector_diff2 = model[\"apple\"] - model[\"tennis\"]\n",
        "vector_diff3 = model[\"mango\"] - model[\"pear\"]\n",
        "vector_diff4 = model[\"apple\"] - model[\"pear\"]"
      ],
      "metadata": {
        "id": "3-9OBiDTNw9L"
      },
      "id": "3-9OBiDTNw9L",
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "np.linalg.norm(vector_diff1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J64fLKdMN6m8",
        "outputId": "a00a666c-c462-4c13-ebc6-9db0235a8495"
      },
      "id": "J64fLKdMN6m8",
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "np.float32(2.98844)"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "np.linalg.norm(vector_diff2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EUCxXuXUN37b",
        "outputId": "dfabe009-59df-4a87-ac37-c0974ca56b86"
      },
      "id": "EUCxXuXUN37b",
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "np.float32(4.210593)"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "np.linalg.norm(vector_diff3)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PhD6skz_Oq1G",
        "outputId": "c84ff947-46e9-4320-e368-3dfe91449cdb"
      },
      "id": "PhD6skz_Oq1G",
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "np.float32(2.7786484)"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "np.linalg.norm(vector_diff4)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6ZvLrqP8OvlT",
        "outputId": "2e0ceb12-8107-4a9b-a5aa-2766f6deb65b"
      },
      "id": "6ZvLrqP8OvlT",
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "np.float32(2.6607358)"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "np.linalg.norm(model[\"apple\"] - model[\"apples\"])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1hK0FhhoO2S-",
        "outputId": "e7501292-8a06-4048-d3b7-a46ed0c6b304"
      },
      "id": "1hK0FhhoO2S-",
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "np.float32(2.3678634)"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Creating Token embeddings..,"
      ],
      "metadata": {
        "id": "0EJt5viBa-6r"
      },
      "id": "0EJt5viBa-6r",
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch"
      ],
      "metadata": {
        "id": "n7OiZuBAbC8Y"
      },
      "id": "n7OiZuBAbC8Y",
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input_ids = torch.tensor([2,3,5,1])"
      ],
      "metadata": {
        "id": "_u6izMMVbKYp"
      },
      "id": "_u6izMMVbKYp",
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input_ids"
      ],
      "metadata": {
        "id": "tt6gvB5mbOpZ",
        "outputId": "6e204272-f9eb-40da-ea2f-302dcc1b525c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "tt6gvB5mbOpZ",
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([2, 3, 5, 1])"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "vocab_size = 6\n",
        "output_dim = 3\n",
        "torch.manual_seed(123)\n",
        "embedding_layer = torch.nn.Embedding(vocab_size,output_dim)"
      ],
      "metadata": {
        "id": "sbRjZRcubP9Y"
      },
      "id": "sbRjZRcubP9Y",
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "embedding_layer.weight"
      ],
      "metadata": {
        "id": "HCFw0HrtpS3R",
        "outputId": "4c53c63f-ca45-401d-f087-283068f79b95",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "HCFw0HrtpS3R",
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Parameter containing:\n",
              "tensor([[ 0.3374, -0.1778, -0.1690],\n",
              "        [ 0.9178,  1.5810,  1.3010],\n",
              "        [ 1.2753, -0.2010, -0.1606],\n",
              "        [-0.4015,  0.9666, -1.1481],\n",
              "        [-1.1589,  0.3255, -0.6315],\n",
              "        [-2.8400, -0.7849, -1.4096]], requires_grad=True)"
            ]
          },
          "metadata": {},
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "embedding_layer(torch.tensor([3]))"
      ],
      "metadata": {
        "id": "F7bSkueJc2yx",
        "outputId": "a05938cb-8966-469a-fc3d-b9d4dcb50c6b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "F7bSkueJc2yx",
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[-0.4015,  0.9666, -1.1481]], grad_fn=<EmbeddingBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "embedding_layer(torch.tensor([2,3,5,1]))"
      ],
      "metadata": {
        "id": "tTilEFrOpjX5",
        "outputId": "c81ba8f0-efd8-4b71-e7c2-b03a391cd870",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "tTilEFrOpjX5",
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 1.2753, -0.2010, -0.1606],\n",
              "        [-0.4015,  0.9666, -1.1481],\n",
              "        [-2.8400, -0.7849, -1.4096],\n",
              "        [ 0.9178,  1.5810,  1.3010]], grad_fn=<EmbeddingBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 57
        }
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.4"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}